# data should be good enough now to perform exploratory analysis
tic()
# split Training into train/test sets
inTrain = createDataPartition(tidy$activity, p = 3/4)[[1]]
training = tidy[inTrain,]
testing = tidy[-inTrain,]
preProc <- preProcess(training[,c(2:42)],method="pca",thresh=.80,scale=TRUE,center=TRUE)
preProc
trainPC <- predict(preProc,training[,c(2:42)])
# use Random Forest model due to more than 2 outcome variables
modelFit <- train(training$activity ~ .,method="rf", data=trainPC)
testPC <- predict(preProc,testing[,c(2:42)])
confusionMatrix(testing$activity, predict(modelFit,testPC))
# todo: document out of sample error estimation of model
toc()
tic()
# split Training into train/test sets
inTrain = createDataPartition(tidy$classe, p = 3/4)[[1]]
training = tidy[inTrain,]
testing = tidy[-inTrain,]
preProc <- preProcess(training[,c(2:42)],method="pca",thresh=.80,scale=TRUE,center=TRUE)
preProc
trainPC <- predict(preProc,training[,c(2:42)])
# use Random Forest model due to more than 2 outcome variables
# modelFit <- train(training$classe ~ .,method="rf", data=trainPC)
# testPC <- predict(preProc,testing[,c(2:42)])
# confusionMatrix(testing$classe, predict(modelFit,testPC))
# todo: document out of sample error estimation of model
toc()
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
setwd("~/scripts/r")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[ inTrain,]
testing = segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~ ., method="rpart",data=training)
training$TotalIntench2
modFit$finalModel
aData <- c(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
aData <- c(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(modFit, newdata <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)), interval=("predict"))
predict(modFit, newdata <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2), interval=("predict"))
modFit <- train(Class ~ ., method="rpart",data=training)
modFit$finalModel
predict(modFit, newdata <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2), interval=("predict"))
View(training)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
a <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
View(a)
predict(modFit, newdata <- a)
View(training)
modFit <- train(Class ~ ., method="rpart",data=training[,3:119])
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
a <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(modFit, newdata <- a)
source('~/.active-rstudio-document', echo=TRUE)
prcomp(training)
View(training)
prcomp(training[,-1])
prcomp(training[,-1])$rotation
source('~/.active-rstudio-document', echo=TRUE)
modelFit <- train(classe ~ .,method="rf", data=training)
inTrain = createDataPartition(tidy$classe, p = 3/4)[[1]]
training = tidy[inTrain,]
testing = tidy[-inTrain,]
View(training)
modelFit <- train(classe ~.,method="rf", data=training,prox=TRUE)
setwd("~/scripts/r")
library(AppliedPredictiveModeling)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
class(olive$Area)
modFit <- train(Area ~.,method="rpart",data=olive)
modFit <- train(Area ~ .,method="rpart",data=olive)
olive
data(olive)
View(olive)
olive = olive[,-1]
View(olive)
newdata = as.data.frame(t(colMeans(olive)))
modFit$finalModel
predict(modFit,newdata)
modFit <- train(Area ~ ., method="tree", data=olive)
library(pgmm)
data(olive)
olive = olive[,-1]
modFit <- train(Area ~ ., method="tree", data=olive)
modFit <- train(Area ~ ., method="rpart", data=olive)
setwd("~/scripts/r")
# Question 1
# Load the cell segmentation data from the AppliedPredictiveModeling package using the commands:
library(AppliedPredictiveModeling)
library(caret)
data(segmentationOriginal)
set.seed(125)
training <- training[,3:119]
modFit <- train(Class ~ ., method="rpart",data=training[,3:119])
modFit$finalModel
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[ inTrain,]
testing = segmentationOriginal[-inTrain,]
set.seed(125)
training <- training[,3:119]
modFit <- train(Class ~ ., method="rpart",data=training[,3:119])
modFit$finalModel
training <- training[,3:119]
View(training)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[ inTrain,]
testing = segmentationOriginal[-inTrain,]
View(training)
set.seed(125)
training <- training[,3:119]
modFit <- train(Class ~ ., method="rpart",data=training)
modFit$finalModel
library(rattle)
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
modFit <- train(Area ~ ., method="rpart", data=olive)
modFit$finalModel
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages(c("car", "evaluate", "ggplot2", "glm2", "jsonlite", "knitr", "lava", "maps", "markdown", "MASS", "memoise", "prodlim", "psych", "Rcpp", "reshape", "reshape2", "RJSONIO", "scales", "yaml"))
install.packages(c("car", "evaluate", "ggplot2", "glm2", "jsonlite",
setwd("~/scripts/r")
library(caret)
library(gbm)
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
library(caret)
library(gbm)
dat = read.csv("./data/gaData.csv")
library(lubridate)
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
gaData <- "./data/gaData.csv"
if(!file.exists(gaData)){
download.file(fileURL, gaData, method="curl")
}
dat = read.csv(gaData)
library(lubridate)
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
View(training)
mod <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
pred <- forecast(mod, h=length(testing$visitsTumblr),level=c(80,95))
pred <- forecast(mod, h=length(training$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(training$visitsTumblr>pred$upper[,2])/length(training$visitsTumblr)
View(dat)
tstrain
mod
!dat[year(dat$date)==2011,]
dat[!year(dat$date)==2011,]
testing <- dat[!year(dat$date)==2011,]
pred <- forecast(mod, h=length(testing$visitsTumblr),level=c(80,95))
pred
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
round(accuracy,1)
round(accuracy,1)
round(accuracy,3)
round(accuracy,2)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
model <- svm(CompressiveStrength ~ ., data = concrete)
model$finalModel
pred <- predict(model,, testing[,-9])
install.packages("hydroGOF")
require(hydroGOF)
pred
View(testing)
rmse(pred,testing$CompressiveStrength)
table(pred)
predValues <- table(pred)
predValues <- data.frame(pred)
View(predValues)
View(testing)
pred <- predict(model,, testing[,-9])
testing[,-9]
View(testing)
dim(pred)
pred <- svm.predict(model,, testing[,-9])
pred <- predict(model, testing[,-9])
rmse(pred,testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
dim(testing)
set.seed(325)
library(e1071)
model <- svm(CompressiveStrength ~ ., data = concrete)
pred <- predict(model,testing[,-9])
dim(pred)
rmse(pred,testing$CompressiveStrength)
(sum((testing$CompressiveStrength - pred)^2)/length(pred))^0.5
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
dim(testing)
# Set the seed to 325
set.seed(325)
library(gbm)
library(forecast)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(AppliedPredictiveModeling)
library(caret)
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
inTrain
detach("package:caret", unload=TRUE)
set.seed(325)
# and fit a support vector machine using the e1071 package to predict
# Compressive Strength using the default settings.
library(e1071)
model <- svm(CompressiveStrength ~ ., data = concrete)
pred <- predict(model,testing[,-9])
(sum((testing$CompressiveStrength - pred)^2)/length(pred))^0.5
accuracy(pred,testing$CompressiveStrength)
library(caret)
library(e1071)
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
detach("package:caret", unload=TRUE)
# Set the seed to 325
set.seed(325)
# and fit a support vector machine using the e1071 package to predict
# Compressive Strength using the default settings.
model <- svm(CompressiveStrength ~ ., data = concrete)
# Predict on the testing set.
pred <- predict(model,testing[,-9])
library(AppliedPredictiveModeling)
library(caret)
library(e1071)
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
detach("package:caret", unload=TRUE)
# Set the seed to 325
set.seed(325)
# and fit a support vector machine using the e1071 package to predict
# Compressive Strength using the default settings.
model <- svm(CompressiveStrength ~ ., data = concrete)
# Predict on the testing set.
pred <- predict(model,testing[,-9])
accuracy(pred,testing$CompressiveStrength)
rmse(pred,testing$CompressiveStrength)
(sum((testing$CompressiveStrength - pred)^2)/length(pred))^0.5
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model <- svm(CompressiveStrength ~ ., data = concrete)
pred <- predict(model,testing[,-9])
accuracy(pred,testing$CompressiveStrength)
(sum((testing$CompressiveStrength - pred)^2)/length(pred))^0.5
library(forecast)
accuracy(pred,testing$CompressiveStrength)
error<-pred-testing$CompressiveStrength
sqrt(mean(error^2))
library(caret)
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
detach("package:caret", unload=TRUE)
# Set the seed to 325
set.seed(325)
# and fit a support vector machine using the e1071 package to predict
# Compressive Strength using the default settings.
model <- svm(CompressiveStrength ~ ., data = concrete)
# Predict on the testing set.
pred <- predict(model,testing[,-9])
# install.packages("hydroGOF")
# require(hydroGOF)
(sum((testing$CompressiveStrength - pred)^2)/length(pred))^0.5
error<-pred-testing$CompressiveStrength
RMSE<-sqrt(mean(error^2))
rmse(pred,testing$CompressiveStrength)
library(forecast)
accuracy(pred,testing$CompressiveStrength)
library(caret)
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
detach("package:caret", unload=TRUE)
# Set the seed to 325
set.seed(325)
# and fit a support vector machine using the e1071 package to predict
# Compressive Strength using the default settings.
model <- svm(CompressiveStrength ~ ., data = training)
# Predict on the testing set.
pred <- predict(model,testing[,-9])
# install.packages("hydroGOF")
# require(hydroGOF)
(sum((testing$CompressiveStrength - pred)^2)/length(pred))^0.5
error<-pred-testing$CompressiveStrength
RMSE<-sqrt(mean(error^2))
rmse(pred,testing$CompressiveStrength)
library(forecast)
accuracy(pred,testing$CompressiveStrength)
library(mass)
library(MASS)
data <- shuttle
View(data)
View(data)
data$use
mod <- glm(use ~ auto, data, family=logit)
mod <- glm(use ~ auto, data, family="logit")
mod <- glm(use ~ auto, data, family="binomial")
View(data)
View(data)
?shuttle
library(data.table)
dt <- data.table(shuttle)
View(dt)
dt[,dt$use=="auto",autolander:=1]
dt[,dt$use=="noauto",autolander:=0]
dt$use
dt[,dt$use=="auto",autolander:=1,0]
dt[,dt$use=="auto",autolander:=1]
dt[,autolander:=0]
View(dt)
dt[,dt$use=="auto",autolander:=1]
dt$use=="auto"
dt$use == as.factor("auto")
dt[dt$use == "auto",autolander:=1]
View(dt)
mod <- glm(autolander ~ wind, data, family="binomial(logit)")
mod <- glm(autolander ~ wind, data, family=binomial(logit))
mod <- glm(autolander ~ wind, data=dt, family=binomial(logit))
summary(mod)
exp(mod$coef)
mod$coef
anova(mod,test="Chisq"
anova(mod,test="Chisq")
anova(mod,test="Chisq")
View(dt)
(0.25131 + 0.03181)/1 + (0.25131 + 0.03181)
exp(mod$coef)
(1.285714+1.032323)/1 + (1.285714+1.032323)
1/exp(0.03181)
mod2 <- glm(autolander ~ wind + magn, data=dt, family=binomial(logit))
summary(mod2)
1/exp(3.201e-02)
?InsectSprays
data <- InsectSprays
sprays <- InsectSprays
View(sprays)
View(sprays)
mod3 <- glm(count ~ spray,data=sprays,family=poisson)
mod3$coef
1/exp(0.05588046)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots(x,y)
knots <- (x,y)
dim(x)
dim(y)
length(x)
length(y)
knots <- (x,y,11)
knots <- (0, 4*pi,11)
knots <- seq(0, 4*pi,11)
splineTerms <- sapply(knots,function(knot) (x > knot) * (x - knot)^2)
xMat <- cbind(1, x, x^2, splineTerms)
yhat <- predict(lm(y ~ xMat - 1))
plot(x, y, frame = FALSE, pch = 21, bg = "lightblue", cex = 2)
lines(x, yhat, col = "red", lwd = 2)
summary(yhat)
yhat
yhat$coef
View(sprays)
y=c(1:10)
x=y-1+rnorm(10)/10
z=c(1:10)
z=z*2
summary(lm(y~x+offset(z)))
z=z*4
summary(lm(y~x+offset(z)))
z=z+5
summary(lm(y~x+offset(z)))
z=z+100
summary(lm(y~x+offset(z)))
z=z/10
summary(lm(y~x+offset(z)))
y=c(1:10)
x=y-1+rnorm(10)/10
z=c(1:10)
z=z*2
lm(y~x+offset(z))$coef
z=z*4
# summary(lm(y~x+offset(z)))
lm(y~x+offset(z))$coef
z=z+5
# summary(lm(y~x+offset(z)))
lm(y~x+offset(z))$coef
z=z+100
# summary(lm(y~x+offset(z)))
lm(y~x+offset(z))$coef
z=z/10
lm(y~x+offset(z))$coef
z=c(1:10)
lm(y~x+offset(z))$coef
z=z*2
lm(y~x+offset(z))$coef
# summary(lm(y~x+offset(z)))
z=z*4
# summary(lm(y~x+offset(z)))
lm(y~x+offset(z))$coef
z=z+5
# summary(lm(y~x+offset(z)))
lm(y~x+offset(z))$coef
z=z+100
# summary(lm(y~x+offset(z)))
lm(y~x+offset(z))$coef
z=z/10
lm(y~x+offset(z))$coef
View(dt)
View(dt)
View(sprays)
View(xMat)
help(offset)
glm(Claims ~ District + Group + Age + offset(log(Holders)),
data = Insurance, family = poisson)
mod1 <- glm(Claims ~ District + Group + Age + offset(log(Holders)),
data = Insurance, family = poisson)
mod1$coef
t <- log(Insurance$Holders)
mod1 <- glm(Claims ~ District + offset(t),
data = Insurance, family = poisson)
mod1$coef
t2 <- log(10) + t
mod2 <- glm(Claims ~ District + offset(t2),
data = Insurance, family = poisson)
mod2$coef
?Insurance
library(shiny)
setwd("~/scripts/r")
runApp("jobwordcloud")
